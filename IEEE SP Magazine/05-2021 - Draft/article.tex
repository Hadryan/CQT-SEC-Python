\documentclass[journal]{IEEEtran}

\usepackage{amsmath,cite,graphicx}

\begin{document}

\title{The Constant-Q Transform Spectral Envelope Coefficients: a musically-adapted timbre feature}

\maketitle


\section{Scope}
%One paragraph describing the article content

%- Aware that some methods are attempting to learn more adapted feature like that 
%- The envelope component can additionally be refined, along with the pitch component
%- Incidentally, the pitch component can be used to identify the pitch/key

% We are presenting a timbre feature better suited to musical data
% We will show how to derive it from the CQT, by decomposing it into a pitch-invariant spectral envelop and a normalized pitch component
% We will show how it compares to the MFCC, commonly-used as the timbre feature, on the NSynth dataset

\IEEEPARstart{T}{imbre} is the attribute of sound which makes, for example, two musical instruments playing the same note sound different. It is generally associated with the spectral (but also temporal) envelope and is typically assumed to be independent from the pitch (but also the loudness) of the sound \cite{moore2004}. While a complex concept to encompass, this article will show how to compute a simple but representative timbre feature ... well-adapted to musical data. 

The feature will be derived from the constant-Q transform (CQT), a log-scaled frequency transform better adapted to musical data \cite{brown1991}, \cite{brown1992}.

The CQT-SEC will compare with the mel-frequency cepstral coefficients (MFCC), on the NSynth dataset, a publicly-available dataset of musical notes \cite{engel2017}.


\section{Relevance}
%One or two paragraphs

% A good pitch-invariant timbre feature can help for identifying musical instruments 
% Additionally, we will show how to decompose the CQT spectrum into a pitch-invariant envelope and a normalized pitch component, which can be reused


\section{Prerequisites}

Basic knowledge of audio signal processing and music information retrieval is required to understand this article, in particular, concepts such as the Fourier transform, convolution, spectral envelope, pitch, CQT, and MFCC.


\section{Problem Statement}

% There is no proper timbre feature, especially for music data.
% People use MFCC, originally designed for speech data, other tried to learn such features
% 





\section{Solution}

\subsection{Observations}

Assumption: A log-spectrum, such as the CQT-spectrum, can be represented as the convolution of a pitch-invariant log-specrtal envelope component (= timbre) and a envelope-normalized pitch component.

\begin{itemize}
\item A pitch change in the audio translates to a linear shift in the log-spectrum.
\item The Fourier transform (FT) of a convolution of two functions is equal to the point-wise product of their FTs (convolution theorem).
\item The magnitude FT is shift-invariant.
\end{itemize}




\section{Numerical Example}
% or "V - Computational Example"

%Equation \ref{eq:sdft} shows ...
%
%\begin{equation}
%\label{eq:sdft}
%\begin{split}
%\underset{0 \leq k < N}{X_k^{(i)}} 
%& = \sum_{n=0}^{N-1} x_{i+n} e^{\frac{-j 2\pi n k}{N}}\\
%& = \sum_{n=0}^{N-1} x_{i+n} e^{\frac{-j 2\pi (n+1) k}{N}} e^{\frac{j 2\pi k}{N}} 
%\end{split}
%\end{equation}

%Figure \ref{fig:dft_kernels} shows ...

%\begin{figure}[htbp]
%	\centering
%	\includegraphics[width=\columnwidth]{dft_kernels.png}
%	\caption{Kernels derived from the Hanning (top-left), Blackman (top-right), triangular (center-left), Parzen (center-right), Gaussian (with $\alpha = 2.5$) (bottom-left), and Kaiser (with $\beta = 0.5$) (bottom-right) windows. The kernels were derived for an $N$-point DFT where $N = 2048$ samples. Only the first 100 coefficients at the bottom-left corner of the $N$-by-$N$ kernels are shown. The values are displayed in log of amplitude.}
%	\label{fig:dft_kernels}
%\end{figure}


\section{What We Have Learned}
% One paragraph

We have shown that ...



\section{Author}

\textit{\textbf{Zafar Rafii}} (zafarrafii@gmail.com) received a PhD in Electrical Engineering and Computer Science from Northwestern University in 2014, and an MS in Electrical Engineering from both Ecole Nationale Superieure de lâ€™Electronique et de ses Applications in France and Illinois Institute of Technology in the US in 2006. He is currently a senior research engineer at Gracenote in the US. He also worked as a research engineer at Audionamix in France. His research interests are centered on audio analysis, somewhere between signal processing, machine learning, and cognitive science, with a predilection for source separation and audio identification.

\bibliographystyle{IEEEtran}
\bibliography{bibliography.bib}

\end{document}
