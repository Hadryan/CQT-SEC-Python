\documentclass[journal]{IEEEtran}

\usepackage{amsmath,cite,graphicx}

\begin{document}

\title{The Constant-Q Transform Spectral Envelope Coefficients: A Timbre Feature Designed for Music}

\maketitle

\section{Scope}

\IEEEPARstart{T}{imbre} is the attribute of sound which makes, for example, two musical instruments playing the same note sound different. It is generally associated with the spectral (but also temporal) envelope and is typically assumed to be independent from the pitch (but also the loudness) of the sound \cite{moore2004}. In this article, we will show how to design a simple but practical pitch-independent timbre feature which is well-adapted to musical data, by deriving it from the constant-Q transform (CQT) \cite{brown1991, brown1992}, a log-scaled frequency transform which matches the notes of the Western music scale. We will show how to decompose the power CQT spectrum into an energy-normalized pitch component and a pitch-independent spectral envelope, the latter from which we will extract a number of timbral coefficients. We will then evaluate the discriminative power of these CQT spectral envelope coefficients (CQT-SEC) on the NSynth dataset \cite{engel2017}, a large-scale dataset of musical notes which is publicly available, comparing them with the mel-frequency cepstral coefficients (MFCCs) \cite{davis1980}, features originally designed for speech recognition but commonly used to characterize timbre in music. 


\section{Relevance}

A timbre feature which is well-adapted to musical data, pitch-independent, and with high discriminative power can find uses in a number of applications, such as similarity detection, sound recognition, and audio classification, in particular, of musical instruments. Additionally, the ability to decompose the spectrum of a sound (here, the power CQT) into a pitch-independent spectral envelope and an energy-normalized pitch component can be useful for audio analysis, transformation, and resynthesis. The energy-normalized pitch component can also potentially be used for pitch identification and melody extraction. 


\section{Prerequisites}

Basic knowledge of audio signal processing and some knowledge of music information retrieval (MIR) are required to understand this article, in particular, concepts such as the Fourier transform, convolution, spectral envelope, pitch, CQT, and MFCCs.


\section{Problem Statement}

The multidimensional nature of timbre makes it an attribute that is tricky to quantify in terms of one single characteristic feature \cite{grey1977}. While it is assumed to be independent from pitch and loudness, it is not really feasible to fully disentangle timbre from those qualities, as timbre is inherently dependent on the spectral content of the sound, which is also defined by its pitch and loudness \cite{moore2004}. Researchers in MIR proposed a number of descriptors to characterize one or more aspects of timbre \cite{peeters2003}, but mostly adopted the MFCCs from the speech recognition community. While the MFCCs have shown 

%More recently, a number of data-driven approaches are attempting to learn some timbre representation, but can be some embeddings used for music resynthesis and that are not necessarily easily interpretable, we will show that we can use simple signal processing techniques to achieve ... typically, by using autoencoders and generative models
%
% style transfer, music generation, 

\cite{engel2017}


\section{Solution}

%- The envelope component can additionally be refined, along with the pitch component
%- Incidentally, the pitch component can be used to identify the pitch/key

convolution theorem: \cite{proakis1995}.

\subsection{Observations}

Assumption: A log-spectrum, such as the CQT-spectrum, can be represented as the convolution of a pitch-invariant log-specrtal envelope component (= timbre) and a envelope-normalized pitch component.

\begin{itemize}
\item A pitch change in the audio translates to a linear shift in the log-spectrum.
\item The Fourier transform (FT) of a convolution of two functions is equal to the point-wise product of their FTs (convolution theorem).
\item The magnitude FT is shift-invariant.
\end{itemize}

% Can think about the extraction of the envelop as a white normalization of the pitch by using a weighting function that normalizes the signal spectral density by the spectrum magnitude, just like in the GCC-PHAT


\section{Numerical Example}
% or "V - Computational Example"

%Equation \ref{eq:sdft} shows ...
%
%\begin{equation}
%\label{eq:sdft}
%\begin{split}
%\underset{0 \leq k < N}{X_k^{(i)}} 
%& = \sum_{n=0}^{N-1} x_{i+n} e^{\frac{-j 2\pi n k}{N}}\\
%& = \sum_{n=0}^{N-1} x_{i+n} e^{\frac{-j 2\pi (n+1) k}{N}} e^{\frac{j 2\pi k}{N}} 
%\end{split}
%\end{equation}

%Figure \ref{fig:dft_kernels} shows ...

%\begin{figure}[htbp]
%	\centering
%	\includegraphics[width=\columnwidth]{dft_kernels.png}
%	\caption{Kernels derived from the Hanning (top-left), Blackman (top-right), triangular (center-left), Parzen (center-right), Gaussian (with $\alpha = 2.5$) (bottom-left), and Kaiser (with $\beta = 0.5$) (bottom-right) windows. The kernels were derived for an $N$-point DFT where $N = 2048$ samples. Only the first 100 coefficients at the bottom-left corner of the $N$-by-$N$ kernels are shown. The values are displayed in log of amplitude.}
%	\label{fig:dft_kernels}
%\end{figure}


\section{What We Have Learned}
% One paragraph

We have shown that ...

%Limitations:
%- just like MFCCs, not very robust to noise, to mixture of musical instruments playing at different pitches



\section{Author}

\textit{\textbf{Zafar Rafii}} (zafarrafii@gmail.com) received a PhD in Electrical Engineering and Computer Science from Northwestern University in 2014, and an MS in Electrical Engineering from both Ecole Nationale Superieure de lâ€™Electronique et de ses Applications in France and Illinois Institute of Technology in the US in 2006. He is currently a senior research engineer at Gracenote in the US. He also worked as a research engineer at Audionamix in France. His research interests are centered on audio analysis, somewhere between signal processing, machine learning, and cognitive science, with a predilection for source separation and audio identification.

\bibliographystyle{IEEEtran}
\bibliography{bibliography.bib}

\end{document}
