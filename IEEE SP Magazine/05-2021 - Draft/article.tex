\documentclass[journal]{IEEEtran}

\usepackage{amsmath,cite,graphicx}

\begin{document}

\title{The Constant-Q Transform Spectral Envelope Coefficients: A Timbre Feature Designed for Music}

\maketitle

\section{Scope}

\IEEEPARstart{T}{imbre} is the attribute of sound which makes, for example, two musical instruments playing the same note sound different. It is generally associated with the spectral (but also temporal) envelope and is typically assumed to be independent from the pitch (but also the loudness) of the sound \cite{moore2004}. In this article, we will show how to design a simple but functional timbre feature which is well-adapted to musical data, by deriving it from the constant-Q transform (CQT) \cite{brown1991, brown1992}, a log-scale frequency transform which matches the Western music scale. We will show how to decompose the CQT spectrum into an energy-normalized pitch component and a pitch-independent spectral envelope, the latter from which we will extract a number of timbral coefficients. We will then evaluate the discriminative power of these CQT spectral envelope coefficients (CQT-SEC) on the NSynth dataset \cite{engel2017}, a large-scale dataset of musical notes which is publicly available, comparing them with the mel-frequency cepstral coefficients (MFCCs) \cite{mermelstein1976}, features originally designed for speech recognition but commonly used to characterize timbre in music. 


\section{Relevance}

A timbre feature which is well-adapted to musical data, pitch-independent, and with high discriminative power can find uses in a number of applications, such as similarity detection, sound recognition, and audio classification, in particular, of musical instruments. Additionally, the ability to decompose the spectrum of a sound (here, the CQT spectrum) into a pitch-independent spectral envelope and an energy-normalized pitch component can be useful for analysis, transformation, and resynthesis of music signals. The energy-normalized pitch component can also potentially be used for pitch identification and melody extraction. 


\section{Prerequisites}

Basic knowledge of audio signal processing and some knowledge of music information retrieval (MIR) \cite{mueller2007} are required to understand this article, in particular, concepts such as the Fourier transform (FT), convolution, spectral envelope, pitch, CQT, and MFCCs. More information about the CQT can also be found in\cite{brown1991, brown1992}.


\section{Problem Statement}

The multidimensional nature of timbre makes it an attribute that is tricky to quantify in terms of one simple characteristic feature \cite{grey1977}. While it is assumed to be independent from pitch and loudness, it is not really feasible to fully disentangle timbre from those qualities, as timbre is inherently dependent on the spectral content of the sound, which is also defined by its pitch and loudness \cite{moore2004}. Researchers in MIR proposed a number of descriptors to characterize one or more aspects of timbre \cite{peeters2011}, but they mostly resort to using the MFCCs when they need one simple timbre feature \cite{mueller2007}. While the MFCCs were shown to be helpful in some MIR tasks, they were initially designed for speech processing applications \cite{mermelstein1976} and are not necessarily adapted to musical data. In particular, they are derived through an old process which makes use of the mel scale, a perceptual scale experimentally designed 80 years ago to approximate the human auditory system's response \cite{stevens1937}. More recently, a number of data-driven approaches attempted to learn some timbral representations from musical data, but generally in terms of implicit embeddings which are tied to a specific trained model \cite{engel2017}, \cite{pons2017}, and not necessarily as explicit and interpretable features such as the MFCCs, which are still usually preferred as the go-to feature to characterize musical timbre by MIR practitioners.


\section{Solution}

We propose the CQT-SECs, a novel timbre feature that is well-adapted to musical data, pitch-independent, simple to derive, interpretable, and functional. We will show how to derive it from the CQT, a log-frequency transform which matches the Western music scale, by first decomposing it into a pitch-independent spectral envelope and an energy-normalized pitch component, and then extracting a number of timbral coefficients from the spectral envelope. 

\subsection{Assumption and Observations}

We start with the assumption that a log-spectrum $X$, in particular, the CQT spectrum, can be represented as the convolution between a pitch-independent spectral envelope $E$ (which mostly contains the timbre information) and an energy-normalized pitch component $P$ (which mostly contains the pitch information), as shown in Equation \ref{eq:assumption}.
\begin{equation}
\label{eq:assumption}
X = E * P
\end{equation}

We then make a first observation that a pitch change in the audio translates to a linear shift in the log-spectrum \cite{brown1991, brown1992}. Assuming that pitch and timbre are independent, this implies that the same musical object at different pitches would have a similar envelope but a shifted pitch component (while two different musical objects at the same pitch would have different envelopes but a similar pitch component). This is summarized in Equation \ref{eq:observation1}.
\begin{equation}
\label{eq:observation1}
\begin{split}
\begin{cases}
X = E * P \\
X' = E' * P' \\
\end{cases}
\Rightarrow E \approx E'
\end{split}
\end{equation}
where $X$, $E$, $P$ and $X'$, $E'$, $P'$ represent the log-spectrum, envelope, and pitch component for a musical object and for a pitch-shifted version of it, respectively.

We make a second observation that the FT of a convolution of two functions is equal to the point-wise product of their FTs, which is also known as the convolution theorem \cite{proakis1995}. This implies that the FT of the log-spectrum would be equal to the point-wise product of the FT of the envelope and the FT of the pitch component. Given the previous observation, this also implies that the FT of the envelope for a musical object and for a pitch-shifted version of it would be equal. This is summarized in equation \ref{eq:observation2}.
\begin{equation}
\label{eq:observation2}
\begin{split}
\begin{cases}
\mathcal{F}(X) = \mathcal{F}(E) \cdot \mathcal{F}(P) \\
\mathcal{F}(X') = \mathcal{F}(E') \cdot \mathcal{F}(P') \\
\end{cases}
\Rightarrow \mathcal{F}(E) \approx \mathcal{F}(E')
\end{split}
\end{equation}
where $\mathcal{F}(.)$ represents the FT function.

We make a third and final observation that the magnitude FT is shift-invariant \cite{proakis1995}. This implies that the FT of the log-spectrum is equal 

Equation \ref{eq:observation3}.
\begin{equation}
\label{eq:observation3}
\begin{split}
\begin{cases}
\mathcal{F}(X) = |\mathcal{F}(X)| \cdot e^{j Arg(\mathcal{F}(X))} \\
\mathcal{F}(X') = |\mathcal{F}(X')| \cdot e^{j Arg(\mathcal{F}(X'))} \\
\end{cases}
\Rightarrow |\mathcal{F}(X)| \approx |\mathcal{F}(X')|
\end{split}
\end{equation}
where $|.|$ and $Arg(.)$ represent the modulus and argument, respectively, for a complex array. 

Given the ..., 

Equation \ref{eq:conclusion}.
\begin{equation}
\label{eq:conclusion}
\begin{split}
&\mathcal{F}(E) \approx |\mathcal{F}(X)| \\
&\Rightarrow E \approx \mathcal{F}^{-1}(|\mathcal{F}(X)|) \\
&\Rightarrow P \approx \mathcal{F}^{-1}(e^{j Arg(\mathcal{F}(X))})
\end{split}
\end{equation}


\subsection{Derivation}


% Can think about the extraction of the envelop as a white normalization of the pitch by using a weighting function that normalizes the signal spectral density by the spectrum magnitude, just like in the GCC-PHAT

%- The envelope component can additionally be refined, along with the pitch component
%- Incidentally, the pitch component can be used to identify the pitch/key



\section{Numerical Example} % or "V - Computational Example"

%Figure \ref{fig:dft_kernels} shows ...

%\begin{figure}[htbp]
%	\centering
%	\includegraphics[width=\columnwidth]{dft_kernels.png}
%	\caption{Kernels derived from the Hanning (top-left), Blackman (top-right), triangular (center-left), Parzen (center-right), Gaussian (with $\alpha = 2.5$) (bottom-left), and Kaiser (with $\beta = 0.5$) (bottom-right) windows. The kernels were derived for an $N$-point DFT where $N = 2048$ samples. Only the first 100 coefficients at the bottom-left corner of the $N$-by-$N$ kernels are shown. The values are displayed in log of amplitude.}
%	\label{fig:dft_kernels}
%\end{figure}


\section{What We Have Learned}

We have shown that ...

%Limitations:
%- just like MFCCs, not very robust to noise, to mixture of musical instruments playing at different pitches



\section{Author}

\textit{\textbf{Zafar Rafii}} (zafarrafii@gmail.com) received a PhD in Electrical Engineering and Computer Science from Northwestern University in 2014, and an MS in Electrical Engineering from both Ecole Nationale Superieure de lâ€™Electronique et de ses Applications in France and Illinois Institute of Technology in the US in 2006. He is currently a senior research engineer at Gracenote in the US. He also worked as a research engineer at Audionamix in France. His research interests are centered on audio analysis, somewhere between signal processing, machine learning, and cognitive science, with a predilection for source separation and audio identification.

\bibliographystyle{IEEEtran}
\bibliography{bibliography.bib}

\end{document}
