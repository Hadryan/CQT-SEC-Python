\documentclass[journal]{IEEEtran}

\usepackage{amsmath,cite,graphicx}

\begin{document}

\title{The Constant-Q Transform Spectral Envelope Coefficients: A Timbre Feature Designed for Music}

\maketitle


\section{Scope}

\IEEEPARstart{T}{imbre} is the attribute of sound which makes, for example, two musical instruments playing the same note sound different. It is generally associated with the spectral (but also temporal) envelope and is typically assumed to be independent from the pitch (but also the loudness) of the sound \cite{moore2004}. Typical attempts to characterize the timbre of musical data is to use to the mel-frequency cepstral coefficients (MFCC) \cite{davis1980}, a feature original designed for speech recognition, while more recently, data-driven approach ...


In this article, we will show how to compute a timbre feature that is well-adapted to musical data. The feature will be derived from the constant-Q transform (CQT), a log-scaled frequency transform which matches the notes of the Western music scale \cite{brown1991}, \cite{brown1992}.

Decompose the CQT into a pitch-invariant spectral envelope and an energy-normalized pitch component. 

CQT spectral envelope coefficients (CQT-SEC)


The CQT-SEC will compare with the , on the NSynth dataset, a publicly-available dataset of musical notes \cite{engel2017}.




%interpretable feature

\section{Relevance}
%One or two paragraphs

% A good timbre feature can be used 
% - can be used for similarity, classification, as inputs to supervised classifiers, as a preprocessing step, ...


% A good pitch-invariant timbre feature can help for identifying musical instruments 
% Additionally, we will show how to decompose the CQT spectrum into a pitch-invariant envelope and a normalized pitch component, which can be reused


\section{Prerequisites}

Basic knowledge of audio signal processing and music information retrieval is required to understand this article, in particular, concepts such as the Fourier transform, convolution, spectral envelope, pitch, CQT, and MFCC.


\section{Problem Statement}

% There is no proper timbre feature, especially for music data.
% People use MFCC, originally designed for speech data, other tried to learn such features
% 


\section{Solution}

%- The envelope component can additionally be refined, along with the pitch component
%- Incidentally, the pitch component can be used to identify the pitch/key

convolution theorem: \cite{proakis1995}.

\subsection{Observations}

Assumption: A log-spectrum, such as the CQT-spectrum, can be represented as the convolution of a pitch-invariant log-specrtal envelope component (= timbre) and a envelope-normalized pitch component.

\begin{itemize}
\item A pitch change in the audio translates to a linear shift in the log-spectrum.
\item The Fourier transform (FT) of a convolution of two functions is equal to the point-wise product of their FTs (convolution theorem).
\item The magnitude FT is shift-invariant.
\end{itemize}

% Can think about the extraction of the envelop as a white normalization of the pitch by using a weighting function that normalizes the signal spectral density by the spectrum magnitude, just like in the GCC-PHAT


\section{Numerical Example}
% or "V - Computational Example"

%Equation \ref{eq:sdft} shows ...
%
%\begin{equation}
%\label{eq:sdft}
%\begin{split}
%\underset{0 \leq k < N}{X_k^{(i)}} 
%& = \sum_{n=0}^{N-1} x_{i+n} e^{\frac{-j 2\pi n k}{N}}\\
%& = \sum_{n=0}^{N-1} x_{i+n} e^{\frac{-j 2\pi (n+1) k}{N}} e^{\frac{j 2\pi k}{N}} 
%\end{split}
%\end{equation}

%Figure \ref{fig:dft_kernels} shows ...

%\begin{figure}[htbp]
%	\centering
%	\includegraphics[width=\columnwidth]{dft_kernels.png}
%	\caption{Kernels derived from the Hanning (top-left), Blackman (top-right), triangular (center-left), Parzen (center-right), Gaussian (with $\alpha = 2.5$) (bottom-left), and Kaiser (with $\beta = 0.5$) (bottom-right) windows. The kernels were derived for an $N$-point DFT where $N = 2048$ samples. Only the first 100 coefficients at the bottom-left corner of the $N$-by-$N$ kernels are shown. The values are displayed in log of amplitude.}
%	\label{fig:dft_kernels}
%\end{figure}


\section{What We Have Learned}
% One paragraph

We have shown that ...



\section{Author}

\textit{\textbf{Zafar Rafii}} (zafarrafii@gmail.com) received a PhD in Electrical Engineering and Computer Science from Northwestern University in 2014, and an MS in Electrical Engineering from both Ecole Nationale Superieure de lâ€™Electronique et de ses Applications in France and Illinois Institute of Technology in the US in 2006. He is currently a senior research engineer at Gracenote in the US. He also worked as a research engineer at Audionamix in France. His research interests are centered on audio analysis, somewhere between signal processing, machine learning, and cognitive science, with a predilection for source separation and audio identification.

\bibliographystyle{IEEEtran}
\bibliography{bibliography.bib}

\end{document}
